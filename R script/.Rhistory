a <- 212
a
setwd('C:\\Users\\iliu2\\Documents\\8.Ad-hoc analytics\\LookAlike')
load('data/data.RData')
ls()
head(all_dt)
cor(all_dt$LIQUORLAND_PTS, all_dt$FCHOICE_ONL_PTS)
colnames(all_dt)
cor_dt <- all_dt[,11:24]
head(cor_dt)
cor(cor_dt)
cor(cor_dt)
cov(cor_dt)
write.csv(cor(cor_dt),file='cor.csv')
setwd('C:\\Users\\iliu2\\Documents\\8.Ad-hoc analytics\\LookAlike')
load('data/data.RData')
ls()
head(all_dt)
library(caret)
set.seed(998)
target <- all_dt$target
df <- all_dt[,-c(62,14,21)]
df$target <- ifelse(df$target %in% c('fco'), 'Y', 'N')
df$target <- as.factor(df$target)
head(df)
training <- df[ inTraining,]
testing  <- df[-inTraining,]
inTraining <- createDataPartition(df$target, p = .75, list = FALSE)
training <- df[ inTraining,]
testing  <- df[-inTraining,]
dim(training)
dim(testing)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 5,
## repeated ten times
repeats = 2)
head(training)
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = T)
gbmFit1
p <- predict(gbmFit1, newdata = testing)
length(p)
dim(testing)
head(testing)
dim(testing)
dim(training)
p <- predict(gbmFit1, newdata = testing[,-59])
length(p)
head(p)
head(testing$target)
gbmImp <- varImp(gbmFit1, scale = T)
gbmImp
p <- predict(gbmFit1, newdata = training[,-59])
length(p)
dim(training)
table(testing$target)
table(traininging$target)
table(training$target)
table(p)
gbmFit1
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
Grid
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
df <- all_dt[,-c(62,14,21)]
df$target <- ifelse(df$target %in% c('fco'), 1, 0)
inTraining <- createDataPartition(df$target, p = .75, list = FALSE)
training <- df[ inTraining,]
testing  <- df[-inTraining,]
# Config
fitControl <- trainControl(## 10-fold CV
method = "none",
number = 5,
## repeated ten times
repeats = 2)
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
# Training
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
?trainControl
fitControl <- trainControl(## 10-fold CV
method = "none",
number = 5,
classProbs =T,
## repeated ten times
repeats = 2)
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
# Training
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
df$target <- as.factor(df$target)
inTraining <- createDataPartition(df$target, p = .75, list = FALSE)
training <- df[ inTraining,]
testing  <- df[-inTraining,]
# Config
fitControl <- trainControl(## 10-fold CV
method = "none",
number = 5,
classProbs =T,
## repeated ten times
repeats = 2)
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
# Training
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
df <- all_dt[,-c(62,14,21)]
df$target <- ifelse(df$target %in% c('fco'), 'Y', 'N')
df$target <- as.factor(df$target)
inTraining <- createDataPartition(df$target, p = .75, list = FALSE)
training <- df[ inTraining,]
testing  <- df[-inTraining,]
# Config
fitControl <- trainControl(## 10-fold CV
method = "none",
number = 5,
classProbs =T,
## repeated ten times
repeats = 2)
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
# Training
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
gbmFit1
summary(gbmFit1)
trellis.par.set(caretTheme())
plot(gbmFit1)
gbmImp <- varImp(gbmFit1, scale = T)
gbmImp
gbmFit1
p <- predict(gbmFit1, newdata = testing[,-59])
length(p)
dim(testing)
head(p)
p <- predict(gbmFit1, newdata = testing[,-59],type = "prob")
p
head(p)
dim(p)
dim(testing)
head(testing)
setwd('C:\\Users\\iliu2\\Documents\\8.Ad-hoc analytics\\LookAlike')
fco_dt <- read.csv('data/fco.csv')
llo_dt <- read.csv('data/llo.csv')
coleso_dt <- read.csv('data/coleso.csv')
eshop_dt <- read.csv('data/eshop.csv')
targeto_dt <- read.csv('data/targeto.csv')
webjet_dt <- read.csv('data/webjet.csv')
webTran_dt <- read.csv('data/webTran.csv')
dim(fco_dt);dim(llo_dt);dim(coleso_dt);dim(eshop_dt);dim(targeto_dt);dim(webjet_dt);dim(webTran_dt)
head(fco_dt)
# fco_dt[which(fco_dt$MOSAIC_DESC=='n/a'),5] <- '-'
fco <- fco_dt[,-c(1,6,7,9,13,17,19,25,27,29,35)]
llo <- llo_dt[,-c(1,6,7,9,13,17,19,25,27,29,35)]
coleso <- coleso_dt[sample(1:nrow(coleso_dt),10000),-c(1,6,7,9,13,17,19,25,27,29,35)]
eshop <- eshop_dt[,-c(1,6,7,9,13,17,19,25,27,29,35)]
targeto <- targeto_dt[sample(1:nrow(targeto_dt),10000),-c(1,6,7,9,13,17,19,25,27,29,35)]
webjet <- webjet_dt[sample(1:nrow(webjet_dt),10000),-c(1,6,7,9,13,17,19,25,27,29,35)]
dim(fco);dim(llo);dim(coleso);dim(eshop);dim(targeto);dim(webjet)
head(fco);str(fco);colnames(fco)
fco$target <- 'fco'
llo$target <- 'llo'
coleso$target <- 'coleso'
eshop$target <- 'eshop'
targeto$target <- 'targeto'
webjet$target <- 'webjet'
fco$col <- 1
llo$col <- 2
coleso$col <- 3
eshop$col <- 4
targeto$col <- 5
webjet$col <- 6
all_dt <- rbind(fco,llo, coleso,eshop,targeto,webjet)
all_dt$target <- as.factor(all_dt$target)
library(caret)
options("na.action")
# Spliting
set.seed(998)
target <- all_dt$target
# df <- cbind(as.data.frame(all_dum), target)
# df <- all_dt[,-ncol(all_dt)]
df <- all_dt[,-c(62,14,21)]
df$target <- ifelse(df$target %in% c('fco'), 'Y', 'N')
df$target <- as.factor(df$target)
inTraining <- createDataPartition(df$target, p = .75, list = FALSE)
training <- df[ inTraining,]
testing  <- df[-inTraining,]
dim(df)
dim(training)
dim(testing)
fitControl <- trainControl(## 10-fold CV
method = "none",
number = 5,
classProbs =T,
## repeated ten times
repeats = 2)
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
# Training
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
gbmFit1
p <- predict(gbmFit1, newdata = testing[,-59],type = "prob")
length(p)
dim(p)
12924/16389
p <- predict(gbmFit1, newdata = training[,-59],type = "prob")
dim(p)
38727/49168
fitControl <- trainControl(## 10-fold CV
method = "none",
#number = 5,
classProbs =T),
## repeated ten times
#repeats = 2)
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
# Training
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
fitControl <- trainControl(## 10-fold CV
method = "none",
#number = 5,
classProbs =T)#,
# repeated ten times
#repeats = 2)
Grid <-  expand.grid(n.trees=150,interaction.depth=3,shrinkage=0.1,n.minobsinnode = 10)
# Training
set.seed(825)
gbmFit1 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl,
tuneGrid = Grid,
metric ='ROC',
## This last option is actually one
## for gbm() that passes through
verbose = T)
gbmFit1
p <- predict(gbmFit1, newdata = training[,-59],type = "prob")
dim(p)
p <- predict(gbmFit1, newdata = testing[,-59],type = "prob")
dim(p)
fitControl <- trainControl(method = "none", number = 10, repeats = 5, classProbs = T, verbose = T)
Grid <-  expand.grid(mtry=17)
fit <- train(target ~ ., data = training, method ="rf", metric ='ROC',
trControl = fitControl, do.trace=100, tuneGrid = Grid)
fit
summary(fit)
fit$modelInfo
fit$results
fit$metric
fit$finalModel
fit$call
fit$control
fit$na.action
gbmFit1$finalModel
gbmFit1$pred
gbmFit1$metric
gbmFit1$modelInfo
fitControl2 <- trainControl(method = "adaptive_cv",
number = 10,
repeats = 2,
## Estimate class probabilities
classProbs = TRUE,
## Evaluate performance using
## the following function
summaryFunction = twoClassSummary,
## Adaptive resampling information:
adaptive = list(min = 10,
alpha = 0.05,
method = "gls",
complete = TRUE))
set.seed(825)
gbmFit2 <- train(target ~ ., data = training,
method = "gbm",
trControl = fitControl2,
preProc = c("center", "scale", "pca"),
tuneLength = 8,verbose = T,
metric = "ROC")
